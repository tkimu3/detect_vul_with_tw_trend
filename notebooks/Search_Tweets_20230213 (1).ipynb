{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8445ef-e56e-487d-84ab-35558b806be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import config\n",
    "import tweepy\n",
    "import os\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cbaeb04-c054-44af-9cf8-42193f981f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# èªè¨¼éƒ¨åˆ†ã‚’é–¢æ•°ã«ã—ã¦ã€clientã‚’è¿”ã™\n",
    "def auth():\n",
    "    # API KEY\n",
    "    CK = config.CK\n",
    "    CS = config.CS\n",
    "    AT = config.AT\n",
    "    AS = config.AS\n",
    "    BT = config.BT\n",
    "\n",
    "    # tweepy setting\n",
    "    # auth = tweepy.OAuthHandler(CK, CS)\n",
    "    # auth.set_access_token(AT, AS)\n",
    "    \n",
    "\n",
    "    # wait_on_rate_limit = True ã¨ã™ã‚‹ã¨ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã‚’ç¢ºèªã—ãªãŒã‚‰å–å¾—å‡¦ç†ã‚’è¡Œã†\n",
    "    client = tweepy.Client(bearer_token = BT,\\\n",
    "                           consumer_key = CK,\\\n",
    "                           consumer_secret = CS,\\\n",
    "                           access_token = AT,\\\n",
    "                           access_token_secret = AS,\\\n",
    "                           wait_on_rate_limit = True)\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f85afb8-d111-421e-84c5-4491c27a66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tweepy.Client()\n",
    "client = auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2728f4c4-a3fe-49e4-b935-455ce42853bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a search_term for searching tweets\n",
    "search_term = \"CVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6773e85-ca34-47c2-baa9-fbd4fcc17f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recent 20 tweets\n",
    "tweets = client.search_recent_tweets(query = search_term,\\\n",
    "                                     max_results = 20\\\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6436376-7514-49d0-910a-057eeec0c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tweepy.client.Response'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fccf5f6b-2b0c-4691-9c22-27a9d347933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @threatintelctr: ğŸš¨ NEW: CVE-2018-1065 ğŸš¨ The netfilter subsystem in the Linux kernel through 4.15.7 mishandles the case of a rule blob thâ€¦\n",
      "RT @sachin_pandey98: How I got $$$$ Bounty within 5 mins for CVE-2017â€“9248 by @7H3P4n7h3R https://t.co/3pJw9RobBq\n",
      "CVE-2023-0590 | Linux Kernel net/sched/sch_api.c qdisc_graft use after free A vulnerability was found in Linux Kernel. It has been declared as problematic. This vulnerability affects the function qdisc_graft of the file net/sched/sch_api.c. The manipulatâ€¦ https://t.co/XVz6Ljwu38\n",
      "CVE-2023-22367 | Ichiran App up to 3.0.x on Android/iOS certificate validation A vulnerability was found in Ichiran App up to 3.0.x. It has been classified as problematic. This affects an unknown part. The manipulation leads to improper certificate validâ€¦ https://t.co/BoxNlKq2qB\n",
      "CVE-2023-22362 | SUSHIRO App on Android log file A vulnerability was found in SUSHIRO App and classified as problematic. Affected by this issue is some unknown functionality. The manipulation leads to sensitive information in log files. This vulnerabilitâ€¦ https://t.co/Os0eHcvF0l\n",
      "CVE-2023-24572 | Dell Command Integration Suite for System Center up to 6.3.x Uninstallation denial of service (dsa-2023-032) A vulnerability has been found in Dell Command Integration Suite for System Center up to 6.3.x and classified as problematic. Afâ€¦ https://t.co/x4D8IMZqeZ\n",
      "CVE-2023-23697 | Dell Command Intel vPro Out of Band up to 4.3.x Uninstallation denial of service (dsa-2023-030) A vulnerability, which was classified as problematic, was found in Dell Command Intel vPro Out of Band up to 4.3.x. Affected is an unknown fuâ€¦ https://t.co/cBwyr5jtRF\n",
      "CVE-2022-48322 | Netgear MR60/MS60/R6900P/R7000P/R7960P/R8000P stack-based overflow (PSV-2022-0155) A vulnerability, which was classified as critical, has been found in Netgear MR60, MS60, R6900P, R7000P, R7960P and R8000P. This issue affects some unknowâ€¦ https://t.co/uKV790NNIK\n",
      "CVE-2022-43460 | Driver Distributor up to 2.2.3.1 Password inadequate encryption A vulnerability classified as problematic was found in Driver Distributor up to 2.2.3.1. This vulnerability affects unknown code of the component Password Handler. The manipâ€¦ https://t.co/PK60eBOCaG\n",
      "CVE-2022-48323 | Sunlogin Sunflower Simplified 1.0.1.43315 HTTP Request /check cmd path traversal A vulnerability classified as critical has been found in Sunlogin Sunflower Simplified 1.0.1.43315. This affects an unknown part of the file /check of the câ€¦ https://t.co/flZdIgUZbp\n",
      "CVE-2022-25937 | glance up to 3.0.8 path traversal A vulnerability was found in glance up to 3.0.8. It has been rated as critical. Affected by this issue is some unknown functionality. The manipulation leads to path traversal. This vulnerability is handlâ€¦ https://t.co/nqbJZbrXBJ\n",
      "CVE-2023-22360 | Screen Creator Advance 2 up to 0.1.1.4 Build01 Project File use after free A vulnerability was found in Screen Creator Advance 2 up to 0.1.1.4 Build01. It has been declared as critical. Affected by this vulnerability is an unknown functiâ€¦ https://t.co/J31Qyr76P1\n",
      "CVE-2023-22353 | Screen Creator Advance up to 0.1.1.4 Build01 Project File out-of-bounds A vulnerability was found in Screen Creator Advance up to 0.1.1.4 Build01. It has been classified as critical. Affected is an unknown function of the component Projeâ€¦ https://t.co/nivexMEKbw\n",
      "CVE-2023-22350 | Creator Advance 2 up to 0.1.1.4 Build01 Project File out-of-bounds A vulnerability was found in Creator Advance 2 up to 0.1.1.4 Build01 and classified as critical. This issue affects some unknown processing of the component Project File â€¦ https://t.co/e671ipQFTI\n",
      "CVE-2023-22349 | Screen Creator Advance 2 up to 0.1.1.4 Build01 Project File out-of-bounds A vulnerability has been found in Screen Creator Advance 2 up to 0.1.1.4 Build01 and classified as critical. This vulnerability affects unknown code of the componeâ€¦ https://t.co/aWL1h1KpZd\n",
      "CVE-2023-22347 | Screen Creator Advance 2 up to 0.1.1.4 Build01 Project File out-of-bounds A vulnerability, which was classified as critical, was found in Screen Creator Advance 2 up to 0.1.1.4 Build01. This affects an unknown part of the component Projeâ€¦ https://t.co/aipUJZWISB\n",
      "CVE-2023-22346 | Screen Creator Advance 2 up to 0.1.1.4 Build01 Project File out-of-bounds A vulnerability, which was classified as critical, has been found in Screen Creator Advance 2 up to 0.1.1.4 Build01. Affected by this issue is some unknown functioâ€¦ https://t.co/Mtvm7vcrLr\n",
      "CVE-2023-22345 | Screen Creator Advance 2 up to 0.1.1.4 Build01 Project File and/or out-of-bounds write A vulnerability classified as critical was found in Screen Creator Advance 2 up to 0.1.1.4 Build01. Affected by this vulnerability is an unknown functâ€¦ https://t.co/49oA6KL055\n",
      "CVE-2023-25727 | phpMyAdmin up to 4.9.10/5.2.0 SQL File cross site scripting A vulnerability classified as problematic has been found in phpMyAdmin up to 4.9.10/5.2.0. Affected is an unknown function of the component SQL File Handler. The manipulation leâ€¦ https://t.co/371wiABmer\n",
      "@BigFranc_ @BigFranc_1 @sinonome007  sinonome007\n",
      "\n",
      "ğŸš¹Cve:Latias\n",
      "\n",
      "ğŸšº ã½ã½ã¡ã‚ƒã¾Â¿ @n_y7xl \n",
      "\n",
      "ãµã‚‰ã‚“ãã•ã‚“ä¸»å‚¬ãŠç–²ã‚Œæ§˜ã§ã™ï¼ï¼\n",
      "ãµã‚‰ã‚“ãã•ã‚“ã‹ã‚‰ã®ãƒãƒ¬ãƒ³ã‚¿ã‚¤ãƒ³æ˜¯éã¨ã‚‚é ‚ããŸã„ã§ã™ï¼wè²´é‡ãª1æ ã ã¨æ€ã„ã¾ã™ãŒã”æ¤œè¨ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ğŸ™‡\n"
     ]
    }
   ],
   "source": [
    "if tweets is not None:\n",
    "    for tweet in tweets[0]:\n",
    "        print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66de6592-09c9-4195-b40b-9a4e850db0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# èªè¨¼éƒ¨åˆ†ã‚’é–¢æ•°ã«ã—ã¦ã€apiã‚’è¿”ã™\n",
    "def create_api():\n",
    "    # API KEY\n",
    "    CK = config.CK\n",
    "    CS = config.CS\n",
    "    AT = config.AT\n",
    "    AS = config.AS\n",
    "\n",
    "    # tweepy setting\n",
    "    auth = tweepy.OAuthHandler(CK, CS)\n",
    "    auth.set_access_token(AT, AS)\n",
    "\n",
    "    # wait_on_rate_limit = True ã¨ã™ã‚‹ã¨ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã‚’ç¢ºèªã—ãªãŒã‚‰å–å¾—å‡¦ç†ã‚’è¡Œã†\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True)\n",
    "\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccd85c3a-4c14-48f0-9af7-dfb38c33bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å‡¦ç†ã‚’é–‹å§‹ã—ãŸæ—¥æ™‚ã‚’å–å¾—ã™ã‚‹\n",
    "start = datetime.datetime.today()\n",
    "startdate=start.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "#ãƒªã‚¹ãƒˆä½œæˆ\n",
    "list_id_str = []\n",
    "list_screen_name = []\n",
    "list_username = []\n",
    "list_userid = []\n",
    "list_created_at = []\n",
    "list_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0a27d90-e4e1-4705-9e96-278cd5c97c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-13 11:43:16.576635\n",
      "2023-02-07 00:00:00\n",
      "2023-02-13 00:00:00\n",
      "2023-02-07T00:00:00+09:00\n",
      "2023-02-13T00:00:00+09:00\n"
     ]
    }
   ],
   "source": [
    "# https://qiita.com/daisuke-aoki/items/30e3d6e84637326ef1da\n",
    "# å–å¾—ã—ãŸã„ãƒ„ã‚¤ãƒ¼ãƒˆæ•°\n",
    "limit = 50000            \n",
    "\n",
    "# å–å¾—å¯¾è±¡ã®ãƒ„ã‚¤ãƒ¼ãƒˆã®æ™‚é–“å¹…ã‚’æŒ‡å®šã™ã‚‹ ã“ã®ä¾‹ã§ã¯å®Ÿè¡Œå‰ã®ï¼’ï¼”æ™‚é–“\n",
    "# isoå½¢å¼ã®UTCæ™‚é–“ã§æŒ‡å®šã—ãªã„ã¨æ­£ã—ãæ™‚é–“æŒ‡å®šãŒã§ããªã„æ¨¡æ§˜ã€‚\n",
    "# æŒ‡å®šã—ãŸæ™‚é–“å¹…ã«ã€limitã§æŒ‡å®šã—ãŸä»¶æ•°ä»¥ä¸Šã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒã‚ã£ã¦ã‚‚limitä»¥ä¸Šã¯å–å¾—ã—ãªã„\n",
    "\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "start_time = now - timedelta(days=6)\n",
    "start_time = start_time.replace(hour = 0, minute = 0, second=0, microsecond=0)\n",
    "print(start_time)\n",
    "end_time = now.replace(hour = 0, minute = 0, second=0, microsecond=0)\n",
    "print(end_time)\n",
    "# now = now.replace(minute=0, second=0, microsecond=0)\n",
    "end_time_tweepy = str(end_time.isoformat()) +'+09:00'\n",
    "# start_time = now - timedelta(days=7) \n",
    "start_time_tweepy = str(start_time.isoformat())+'+09:00'\n",
    "print(start_time_tweepy)\n",
    "print(end_time_tweepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04f49e3c-b5c0-4776-b5f3-a5fb000d65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                created_at            author_id  \\\n",
      "0  1624785106333310984  2023-02-12T14:58:51.000Z  1530877110226665472   \n",
      "0  1624784970509348866  2023-02-12T14:58:18.000Z  1388217926541447169   \n",
      "0  1624784895871680512  2023-02-12T14:58:00.000Z  1388217926541447169   \n",
      "0  1624784592413532160  2023-02-12T14:56:48.000Z            941026441   \n",
      "0  1624784417171419140  2023-02-12T14:56:06.000Z  1322315722287099909   \n",
      "0  1624784406987567104  2023-02-12T14:56:04.000Z  1322315722287099909   \n",
      "0  1624784230352924677  2023-02-12T14:55:22.000Z  1464325401224912901   \n",
      "0  1624784198950158337  2023-02-12T14:55:14.000Z  1474773760968384521   \n",
      "0  1624783987607764993  2023-02-12T14:54:24.000Z   861783161801326592   \n",
      "0  1624783395438972932  2023-02-12T14:52:03.000Z  1425939384373764102   \n",
      "\n",
      "                                      public_metrics  \\\n",
      "0  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
      "0  {'retweet_count': 39, 'reply_count': 0, 'like_...   \n",
      "0  {'retweet_count': 57, 'reply_count': 0, 'like_...   \n",
      "0  {'retweet_count': 57, 'reply_count': 0, 'like_...   \n",
      "0  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
      "0  {'retweet_count': 2, 'reply_count': 1, 'like_c...   \n",
      "0  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
      "0  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
      "0  {'retweet_count': 39, 'reply_count': 0, 'like_...   \n",
      "0  {'retweet_count': 3, 'reply_count': 0, 'like_c...   \n",
      "\n",
      "                                                text edit_history_tweet_ids  \n",
      "0           @cve_0q @gorgeous4ew Ø§Ù†Øª Ø§Ù„ÙŠ Ù…Ø§Ø³ÙˆÙŠØª Ø´Ø¦ !  [1624785106333310984]  \n",
      "0  RT @_0xf4n9x_: CVE-2023-0669 GoAnywhere MFT De...  [1624784970509348866]  \n",
      "0  RT @pdnuclei: Scanning for GoAnywhere MFT - Re...  [1624784895871680512]  \n",
      "0  RT @pdnuclei: Scanning for GoAnywhere MFT - Re...  [1624784592413532160]  \n",
      "0  PoC Available:\\n\\n@github : https://t.co/RBVYq...  [1624784417171419140]  \n",
      "0  CVE-2023-0669 #Vulnerability - A pre-authentic...  [1624784406987567104]  \n",
      "0  @HanLeviVan @cve_0q @ASCom0 Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡...  [1624784230352924677]  \n",
      "0  ESXIArgs Ransomware analysis.\\n\\nESXIArgs Rans...  [1624784198950158337]  \n",
      "0  RT @_0xf4n9x_: CVE-2023-0669 GoAnywhere MFT De...  [1624783987607764993]  \n",
      "0  RT @spsaude_: âš ï¸ O Centro de VigilÃ¢ncia Epidem...  [1624783395438972932]  \n"
     ]
    }
   ],
   "source": [
    "# f = codecs.open('tweets[{}]_{}.txt'.format(search_term,startdate), 'w', 'utf-8')\n",
    "client = auth()\n",
    "#itr = tweepy.Cursor(api.followers_ids, screen_name = screen_name, count=5000,cursor=cursor).pages()\n",
    "# itr = tweepy.Cursor(api.search_tweets, q = search_term, tweet_mode=\"extended\", count = 200, cursor=cursor).pages()\n",
    "# print(type(itr))\n",
    "# try:\n",
    "#     for tweet in itr.next():\n",
    "#         # print(tweet._json)\n",
    "#         try:\n",
    "#             # user = api.get_user(follower_id)\n",
    "#             # tweet_info = [tweet.id_str, tweet.screen_name, tweet.name, tweet.created_at, tweet.full_text]\n",
    "#             tweet_info = [tweet._json['id_str'], tweet._json['user']['screen_name'], tweet._json['user']['name'], tweet._json['user']['id'], tweet._json['created_at'], tweet._json['full_text']]\n",
    "#             list_id_str.append(tweet._json['id_str'])\n",
    "#             list_screen_name.append(tweet._json['user']['screen_name'])\n",
    "#             list_username.append(tweet._json['user']['name'])\n",
    "#             list_userid.append(tweet._json['user']['id'])\n",
    "#             list_created_at.append(tweet._json['created_at'])\n",
    "#             list_text.append(tweet._json['full_text'])\n",
    "#             print(tweet_info)\n",
    "#             f.write(str(tweet_info))\n",
    "#             f.write(\"\\n\")\n",
    "#         except tweepy.error.TweepError as e:\n",
    "#             print(\"ã‚¨ãƒ©ãƒ¼ã‚ã‚Š\")\n",
    "#             print(e.reason)\n",
    "#             f.write(e.reason + \"\\n\")\n",
    "# except ConnectionError as e:\n",
    "#     print(e.reason)\n",
    "#     f.write(e.reason + \"\\n\")\n",
    "# f.close()\n",
    "\n",
    "#ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ\n",
    "# df=pd.DataFrame({'id_str':list_id_str,'screen_name':list_screen_name,'username':list_username,'created_at':list_created_at, 'text':list_text})\n",
    "df_tweet = pd.DataFrame()\n",
    "for tweet in tweepy.Paginator(client.search_recent_tweets,\\\n",
    "                              query = search_term,\\\n",
    "                              start_time=start_time_tweepy,\\\n",
    "                              end_time=end_time_tweepy,\\\n",
    "                              tweet_fields=['id','created_at','text','author_id','public_metrics',],\\\n",
    "                              # expansions='author_id',\\\n",
    "                              # user_fields='description',\\\n",
    "                              #user_fields=['id','name','username',],\\\n",
    "                              max_results = 100).flatten(limit = limit):\n",
    "    # print(dir(tweet))\n",
    "    df_tweet = pd.concat([df_tweet, pd.DataFrame([tweet.data])])\n",
    "    #df_tweet = pd.concat([df_tweet, pd.DataFrame([tweet.data], ignore_index=True)])\n",
    "\n",
    "print(df_tweet)\n",
    "\n",
    "#æœ¬æ—¥ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸€éƒ¨ã«è¨­å®š\n",
    "# d = datetime.datetime.today()\n",
    "# filename=d.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# df.to_csv(filename+\"_\" + search_term + \".csv\", index=False,header=False)\n",
    "# f = codecs.open('tweets[{}]_{}.txt'.format(search_term,startdate), 'w', 'utf-8')\n",
    "# print(\"Start \" + startdate)\n",
    "# print(\"End \" + filename + \": å–å¾—ä»¶æ•°ã¯\"+str(len(df))+\"ä»¶ã§ã™\")\n",
    "# f.write(\"Start \" + startdate)\n",
    "# f.write(\"\\n\")\n",
    "# f.write(\"End \" + filename + \": å–å¾—ä»¶æ•°ã¯\"+str(len(df))+\"ä»¶ã§ã™\")\n",
    "# f.write(\"\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c009c25f-1e23-4fc6-a41b-7dc42dc4c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230207-20230213\n"
     ]
    }
   ],
   "source": [
    "filename = start_time.strftime(\"%Y%m%d\") + \"-\" + end_time.strftime(\"%Y%m%d\") \n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9319c3d0-bd9b-42a7-b9a2-9af8a54b3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv(filename + \".csv\", index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
